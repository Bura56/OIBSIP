import os
from flask import Flask, render_template, request, jsonify,url_for
from werkzeug.utils import secure_filename
import os
from dotenv import load_dotenv
import openai
import requests
from gtts import gTTS
import asyncio
import string
import random


#load the api keys from the the .env file
load_dotenv()
#
hugging_face = os.getenv('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')
open_ai_key = os.getenv('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')
#
openai.api_key = open_ai_key

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['ALLOWED_EXTENSIONS'] = {'webm'}


def get_anwer_openai(quastion):
    completion = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages = [{"role": "system", "content" : "I want you to act like a helpful Voice assistant and help the user in informative way"},
                            {"role": "user", "content" : "Give a Brief of updated news and all the things that are happpenig in the world"},
                            {"role":"user","content":quastion}
                ]
            )
    
    return completion['choices'][0]['message']['content']


###
def text_to_audio(text,filrname):
    tts = gTTS(text)
    tts.save(f'static/audio/{filrname}.mp3')

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/chat', methods=['POST'])
def chat():
    if 'audio' in request.files:
        audio = request.files['audio']
        if audio and allowed_file(audio.filename):
            filename = secure_filename(audio.filename)
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            audio.save(filepath)
            transcription = process_audio(filepath)
            return jsonify({'text': transcription})

    text = request.form.get('text')
    if text:
        response = process_text(text)
        return {'text': response['text'],'voice': url_for('static', filename='audio/' + response['voice'])}

    return jsonify({'text': 'Invalid request'})

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']

def process_audio(filepath):
    # Placeholder function for processing audio (speech-to-text transcription)
    # Replace this with your own implementation using libraries like SpeechRecognition or DeepSpeech
    #return 'hello This is a placeholder transcription for audio'
    API_URL = "https://api-inference.huggingface.co/models/jonatasgrosman/wav2vec2-large-xlsr-53-english"
    headers = {"Authorization": hugging_face}
    with open(filepath, "rb") as f:
        data = f.read()
    response = requests.post(API_URL, headers=headers, data=data)
    data = response.json()
    return data['text']

def process_text(text):
    # Placeholder function for processing user's text input
    # Replace this with your own implementation
    return_text = get_anwer_openai(text)
    #asyncio.run(text_to_audio(return_text))
    # generating random strings
    res = ''.join(random.choices(string.ascii_uppercase +
                             string.digits, k=8))
    text_to_audio(return_text,res)
    return {"text":return_text,"voice": f"{res}.mp3"}


if __name__ == '__main__':
    app.run(debug=True)